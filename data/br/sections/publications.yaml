# section information
section:
  name: Publicações
  id: publications
  enable: true
  weight: 7
  showOnNavbar: true
  # Can optionally hide the title in sections
  # hideTitle: true

# filter buttons
buttons:
- name: All
  filter: "all"
- name: "Test Smells"
  filter: "testsmells"
- name: "Unit Tests"
  filter: "unittest"
- name: "Controlled Experiment"
  filter: "controlled_experiment"
- name: "Data Mining"
  filter: "data_mining"

# your publications
publications:
- title: "SNUTS.js: Sniffing Nasty Unit Test Smells in Javascript - A3"
  publishedIn:
    name: "Brazilian Symposium on Software Engineering"
    date: 2024
    url: https://doi.org/10.5753/sbes.2024.3563
  authors:
  - name: Jhonatan Oliveira (UNEB)
    url: https://orcid.org/
  - name: Luigi Mateus (UNEB)
    url: https://orcid.org/
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Larissa Rocha (UNEB / UEFS)
    url: https://orcid.org/
  paper:
    summary: "Test smells indicate potential issues or weaknesses within the test code, which can compromise its effectiveness and maintainability. They highlight areas where improvements can enhance the overall quality of the test suite or testing practices. For instance, an example of a test smell is the Anonymous Test, where the test’s name lacks descriptive information about its function or purpose. Addressing these test smells can result in more robust and maintainable test suites, thus improving the reliability of the testing process. Despite significant research on these issues, tools are scarce for automatically detecting them, particularly in certain programming languages such as JavaScript. In the current landscape, existing test smell detection tools for JavaScript lack intuitiveness and graphical interfaces, and require extensive configuration, which may lead to low adoption within the developer community. To address this gap, we propose SNUTS.js, a tool designed to streamline the detection of test smells in JavaScript. Designed as an API, SNUTS.js offers versatility, allowing integration with various tools and environments. This tool goes beyond existing solutions by identifying previously undetected test smells, including the Anonymous Test, Comments Only Test, Overcommented, General Fixture, Transcripting Test, and Sensitive Equality. We also introduce a new test smell termed Test Without Description, which denotes a test case lacking descriptive text. In a preliminary evaluation, we constructed a dataset of tests sourced from real-world projects on GitHub. Through manual analysis, we identified 285 instances of test smells. SNUTS.js demonstrated a detection accuracy of 100% for three specific types of test smells, Anonymous Test, Overcommented, and General Fixture, all tailored to the JavaScript environment. Link to the video: https://youtu.be/89z0jy4Nu0s"
    url: https://doi.org/10.5753/sbes.2024.3563
  categories: ["Test Smells"]
  tags: ["Test Smells", "JavaScript", "Test Quality", "Tool"]

- title: "How Aware Are We of Test Smells in Quantum Software Systems? A Preliminary Empirical Evaluation - B1"
  publishedIn:
    name: "SBQS '24: Proceedings of the XXIII Brazilian Symposium on Software Quality"
    date: 2024
    url: https://dl.acm.org/doi/10.1145/3701625.3701676
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Larissa Rocha (UNEB / UEFS)
    url: https://orcid.org/
  - name: Carla Bezerra (UFT)
    url: https://orcid.org/
  - name: Márcio Ribeiro (UFAL)
    url: https://orcid.org/
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/

  paper:
    summary: "Context: With the rapid progress of quantum computing, Quantum Software Engineering (QSE) is establishing itself as an essential discipline to support developers throughout all stages of quantum software development. The area of testing in quantum systems has received greater attention in research on this topic to guarantee the quality and reliability of these technologies. Objective: This paper presents an empirical study focused on the testing of quantum software at its classical layer. Specifically, it aims to identify and analyze the unique characteristics of quantum software tests, particularly in terms of Test Smells, their distribution, recurrence, and differences compared to classical software tests. Method: We used two sets of software from previous studies, one comprising 12 quantum software and the other comprising 80 classical software. From these datasets, we conducted an analysis to detect 10 test smells, allowing us to map their dispersion in quantum software, identify their specific characteristics, and draw comparisons with classical software. Results: Our findings reveal a high dispersion of test smells of 51% in quantum software. Furthermore, quantum tests exhibit statistical differences from classical software tests, with the most outlier being Conditional Test Logic, which is 20% more frequent than in classical software. Conclusions: The insights gained from this study can contribute to enhancing the quality, maintainability, and readability of tests written for the classical layer of quantum software. Ultimately, this can improve the overall understanding and quality of quantum software."
    url: https://dl.acm.org/doi/10.1145/3701625.3701676
  categories: ["Test Smells"]
  tags: ["Test Smells", "JavaScript", "Test Quality", "Tool"]

- title: "An empirical evaluation of RAIDE: a semi-automated approach for test smells detection and refactoring - A4"
  publishedIn:
    name: Science of Computer Programming
    date: 2023
    url: https://doi.org/10.1016/j.scico.2023.103013
  authors:
  - name: Railana Santana (UFBA)
    url: https://example.com
  - name: Luana Martins (UFBA)
    url: https://example.com
  - name: Tássio Virgínio (IFTO)
    url: https://example.com
  - name: Larissa Rocha (UFBA)
    url: https://example.com
  - name: Heitor Costa (UFLA)
    url: https://example.com
  - name: Ivan Machado (UFBA)
    url: https://example.com    
  paper:
    summary: Effective test code refactoring is essential for maintaining the quality and efficiency of software development. Automated support for test code refactoring can significantly enhance its cost-effectiveness. However, there is limited evidence on the effectiveness of such automated support, especially for addressing Assertion Roulette and Duplicate Assert test smells. To address this gap, we present RAIDE, an Eclipse IDE plugin that provides an easy-to-use approach to identifying and refactoring test smells. In this study, we conduct a controlled experiment with twenty participants to evaluate RAIDE's capability to detect and refactor Assertion Roulette and Duplicate Assert test smells. The results demonstrate that RAIDE outperforms comparable state-of-the-art approaches in detecting test smells, and can detect and refactor test smells in a fraction of the time. Our findings highlight the potential benefits of automated test code refactoring support for improving the efficiency and effectiveness of software development, and suggest avenues for future research to extend and evaluate RAIDE for handling other test smells and refactoring techniques.
    url: https://doi.org/10.1016/j.scico.2023.103013
  categories: ["testsmells","tests","smells"]
  tags: ["Teste Smells", "Tests", "Smells"]

- title: "Refactoring Assertion Roulette and Duplicate Assert test smells: a controlled experiment - B2"
  publishedIn:
    name: Iberoamerican Conference on Software Engineering (CIbSE)
    date: 2022
    url: https://cibse2022.frc.utn.edu.ar/conferencia-principal-2/
  authors:
  - name: Railana Santana (UFBA)
    url: https://example.com
  - name: Luana Martins (UFBA)
    url: https://example.com
  - name: Tássio Virgínio (IFTO)
    url: https://tassiovirginio.github.io
  - name: Larissa Soares (UFBA)
    url: https://example.com
  - name: Heitor Costa (UFLA)
    url: https://example.com
  - name: Ivan Machado (UFBA)
    url: https://example.com
  paper:
    summary: "Test smells can reduce the developers' ability to interact with the test code. Refactoring test code offers a safe strategy to handle test smells. However, the manual refactoring activity is not a trivial process, and it is often tedious and error-prone. This study aims to evaluate RAIDE, a tool for automatic identification and refactoring of test smells. We present an empirical assessment of RAIDE, in which we analyzed its capability at refactoring Assertion Roulette and Duplicate Assert test smells and compared the results against both manual refactoring and a state-of-the-art approach. The results show that RAIDE provides a faster and more intuitive approach for handling test smells than using an automated tool for smells detection combined with manual refactoring"
    url: https://sol.sbc.org.br/index.php/cibse/article/view/20977
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "Avaliação empírica da geração automatizada de testes desoftware sob a perspectiva de Test Smells"
  publishedIn:
    name: "ANAIS ESTENDIDOS DO CONGRESSO BRASILEIRO DE SOFTWARE: TEORIA E PRÁTICA (CBSOFT)"
    date: 2021
    url: https://sol.sbc.org.br/index.php/cbsoft_estendido/article/view/17292
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: O teste de software é uma atividade-chave para o desenvolvimento de software de qualidade, sendo tão ou mais custoso do que o desenvolvimento do código de produção. De modo a reduzir os custos de projetos de software, o uso de ferramentas de geração automatizada de testes, tais como Randoop e Evosuite tem sido fortemente encorajado. No entanto, é necessário obter evidências sobre como o uso dessas ferramentas afeta a qualidade dos testes. Neste sentido, o presente estudo apresenta uma avaliação empírica da qualidade de testes gerados automaticamente, sob a perspectiva de test smells. O estudo contemplou o desenvolvimento de uma ferramenta open source de coleta e análise automatizada de test smells, a JNose Test, no desenvolvimento da ferramenta foi realizado estudo utilizando 11 projetos open source para verificar a relação entre test smells e a cobertura dos testes, e posteriormente no segundo estudo que avaliou a qualidade de testes gerados automaticamente para 21 projetos open source. No primeiro estudo encontramos relações fortes entre métricas de cobertura e test smells, e no segundo estudo os resultados indicam uma alta difusão dos test smells e co-ocorrências entre diferentes tipos de test smells nos projetos avaliados. Além disso, foi identificada uma alta difusão de test smells nos códigos de teste gerados pelas ferramentas Evosuite e Randoop que, frequentemente, estão correlacionados.
    url: https://sol.sbc.org.br/index.php/cbsoft_estendido/article/view/17292
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "On the test smells detection: an empirical study on the JNose Test accuracy - A4"
  publishedIn:
    name: "JOURNAL OF SOFTWARE ENGINEERING RESEARCH AND DEVELOPMENT"
    date: 2021
    url: https://sol.sbc.org.br/journals/index.php/jserd/article/view/1893
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Luana Martins (UFBA)
    url: https://orcid.org/0000-0001-6340-7615
  - name: Railana Santana (UFBA)
    url: https://orcid.org/0000-0002-1153-8960
  - name: Adriana Cruz (UFLA)
    url: https://orcid.org/0000-0001-5196-6356
  - name: Larissa Rocha (UFBA)
    url: https://orcid.org/0000-0002-8069-5249
  - name: Heitor Costa (UFLA)
    url: https://orcid.org/0000-0002-9903-7414
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: "Several strategies have supported test quality measurement and analysis. For example, code coverage, a widely used one, enables verification of the test case to cover as many source code branches as possible. Another set of affordable strategies to evaluate the test code quality exists, such as test smells analysis. Test smells are poor design choices in test code implementation, and their occurrence might reduce the test suite quality. A practical and largescale test smells identification depends on automated tool support. Otherwise, test smells analysis could become a cost-ineffective strategy. In an earlier study, we proposed the JNose Test, automated tool support to detect test smells and analyze test suite quality from the test smells perspective. This study extends the previous one in two directions: i) we implemented the JNose-Core, an API encompassing the test smells detection rules. Through an extensible architecture, the tool is now capable of accomodating new detection rules or programming languages; and ii) we performed an empirical study to evaluate the JNose Test effectiveness and compare it against the state-of-the-art tool, the tsDetect. Results showed that the JNose-Core precision score ranges from 91% to 100%, and the recall score from 89% to 100%. It also presented a slight improvement in the test smells detection rules compared to the tsDetect for the test smells detection at the class level."
    url: "https://doi.org/10.5753/jserd.2021.1893"
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "JNose: Java Test Smell Detector - A3"
  publishedIn:
    name: "Brazilian Symposium on Software Engineering"
    date: 2020
    url: https://dl.acm.org/doi/10.1145/3422392.3422499
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Luana Martins (UFBA)
    url: https://orcid.org/0000-0001-6340-7615
  - name: Railana Santana (UFBA)
    url: https://orcid.org/0000-0002-1153-8960
  - name: Adriana Cruz (UFLA)
    url: https://orcid.org/0000-0001-5196-6356
  - name: Larissa Rocha (UFBA)
    url: https://orcid.org/0000-0002-8069-5249
  - name: Heitor Costa (UFLA)
    url: https://orcid.org/0000-0002-9903-7414
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: "Several strategies have been proposed for test quality measurement and analysis. Code coverage is likely the most widely used one. It enables to verify the ability of a test case to cover as many source code branches as possible. Although code coverage has been widely used, novel strategies have been recently employed. It is the case of test smells analysis, which has been introduced as an affordable strategy to evaluate the quality of test code. Test smells are poor design choices in implementation, and their occurrence in test code might reduce the quality of test suites. Test smells identification is clearly dependent on tool support, otherwise it could become a cost-ineffective strategy. However, as far as we know, there is no tool that combines code coverage and test smells to address test quality measurement. In this work, we present the JNose Test, a tool aimed to analyze test suite quality in the perspective of test smells. JNose Test detects code coverage and software evolution metrics and a set of test smells throughout software versions."
    url: https://doi.org/10.1145/3422392.3422499
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "An empirical study of automatically-generated tests from the perspective of test smells - A3"
  publishedIn:
    name: "SBES '20: Proceedings of the XXXIV Brazilian Symposium on Software Engineering"
    date: 2020
    url: https://doi.org/10.1145/3422392.3422412
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Luana Martins (UFBA)
    url: https://orcid.org/0000-0001-6340-7615
  - name: Railana Santana (UFBA)
    url: https://orcid.org/0000-0002-1153-8960
  - name: Larissa Rocha (UFBA)
    url: https://orcid.org/0000-0002-8069-5249
  - name: Heitor Costa (UFLA)
    url: https://orcid.org/0000-0002-9903-7414
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: "Developing test code can be as or more expensive than developing production code. Commonly, developers use automated unit test generators to speed up software testing. The purpose of such tools is to shorten production time without decreasing code quality. Nonetheless, unit tests usually do not have a quality check layer above testing code, which might be hard to guarantee the quality of the generated tests. A strategy to verify the tests quality is to analyze the presence of test smells in test code. Test smells are characteristics in the test code that possibly indicate weaknesses in test design and implementation. Their presence could be used as a quality indicator. In this paper, we present an empirical study to analyze the quality of unit test code generated by automated test tools. We compare the tests generated by two tools (Randoop and Evo- Suite) with the existing unit test suite of twenty-one open-source Java projects. We analyze the unit test code to detect the presence of nineteen types of test smells. The results indicated significant differences in the unit test quality when comparing data from the automated unit test generators and existing unit test suites."
    url: https://doi.org/10.1145/3422392.3422412
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "RAIDE: a tool for Assertion Roulette and Duplicate Assert identification and refactoring - A3"
  publishedIn:
    name: "SBES '20: Proceedings of the XXXIV Brazilian Symposium on Software Engineering"
    date: 2020
    url: https://doi.org/10.1145/3422392.3422510
  authors:
  - name: Railana Santana (UFBA)
    url: https://orcid.org/0000-0002-1153-8960
  - name: Luana Martins (UFBA)
    url: https://orcid.org/0000-0001-6340-7615
  - name: Larissa Rocha (UFBA)
    url: https://orcid.org/0000-0002-8069-5249
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Adriana Cruz (UFLA)
    url: https://orcid.org/0000-0001-5196-6356
  - name: Heitor Costa (UFLA)
    url: https://orcid.org/0000-0002-9903-7414
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: "Test smells are fragments of code that can affect the comprehensibility and the maintainability of the test code. Preventing, detecting, and correcting test smells are tasks that may require a lot of effort, and might not scale to large-sized projects when carried out manually. Currently, there are many tools available to support test smells detection. However, they usually do not provide neither a user-friendly interface nor automated support for refactoring the test code to remove test smells. In this work, we propose RAIDE, an open-source and IDE-integrated tool. RAIDE assists testers with an environment for automated detection of lines of code affected by test smells, as well as a semi-automated refactoring for Java projects using the JUnit framework."
    url: https://doi.org/10.1145/3422392.3422510
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "On the influence of Test Smells on Test Coverage - A3"
  publishedIn:
    name: "SBES '20: Proceedings of the XXXIV Brazilian Symposium on Software Engineering"
    date: 2019
    url: https://dl.acm.org/doi/10.1145/3350768.3350775
  authors:
  - name: Tássio Virgínio (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Railana Santana (UFBA)
    url: https://orcid.org/0000-0002-1153-8960
  - name: Luana Martins (UFBA)
    url: https://orcid.org/0000-0001-6340-7615
  - name: Larissa Rocha (UFBA)
    url: https://orcid.org/0000-0002-8069-5249
  - name: Heitor Costa (UFLA)
    url: https://orcid.org/0000-0002-9903-7414
  - name: Ivan Machado (UFBA)
    url: https://orcid.org/0000-0001-9027-2293
  paper:
    summary: "Software testing is a key practice in the software quality assurance process. Usually, the quality of a test is not analyzed before its execution, i.e., there are no tests to check the tests. When the quality of tests is not guaranteed, it may impair the quality of the software. Test Smells are an alternative to indicate problems in the test code that can affect test maintainability, more specifically readability and comprehension. This study investigates correlations between test coverage and test smells types. We also introduce the JNose Test, a tool to automate test smells detection. We analyzed 11 open source projects and detected 21 types of smells and 10 different test coverage metrics to each test class. We identified 63 out of 210 calculated correlations. Our results show that there is a relationship between test smells and test coverage, in which test smells may influence code coverage. Our findings might support software testers and help them understand the behavior and consequences of poorly written and designed tests."
    url: https://doi.org/10.1145/3350768.3350775
  categories: ["Test Smells"]
  tags: ["Test Smells", "Unit Tests", "Controlled Experiment"]

- title: "Association of Social Data - A2"
  publishedIn:
    name: "GLOBAL JOURNAL OF HUMAN SOCIAL SCIENCES Vol.14 Issue.10 - ISSN-0975-587X"
    date: 2014
    url: https://globaljournals.org/GJHSS_Volume14/6-Association-of-Social-Data.pdf
  authors:
  - name: Diego C. Rodrigues (IFTO)
    url: https://orcid.org/
  - name: Marcelo Rocha Lisbon (IFTO)
    url: https://orcid.org/
  - name:  Jucelino Santos (IFTO)
    url: https://orcid.org/
  - name: Tássio Virginio  (IFTO)
    url: https://orcid.org/0000-0001-6259-4957
  - name: Wilmar Borges (IFTO)
    url: https://orcid.org/
  paper:
    summary: "According to the ILO (International Labour Organisation) about 218 million children between 5 and 17 years working in the world, of which 50% have jobs at risk. On the basis of this information, arising questions on how to understand and find the factors that comprise the ratings of child labour, and which properties are important to analyze these cases.With the use of data mining techniques to find valid patterns on Brazilian social databases were evaluated data of child labour in the State of Tocantins (located north of Brazil with a territory of 277 thousand and composed of 139 cities).This work aims to identify factors that are deterministic to the practice of child labour and their relationships with financial indicators, educational, social, and regional generating information that are not explicit in the Government database, thus enabling a better monitoring and updating policies to that end."
    url: https://globaljournals.org/GJHSS_Volume14/6-Association-of-Social-Data.pdf
  categories: ["Data Mining"]
  tags: ["Data Mining", "Social Data", "Child Labor"]